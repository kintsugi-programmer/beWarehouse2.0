# DAIDP

## Table of Contents
- [DAIDP](#daidp)
  - [Table of Contents](#table-of-contents)
  - [Session 1 : Introduction](#session-1--introduction)
  - [Session 2 : Product Management](#session-2--product-management)
  - [Session 3 : Why AI Products are different ?](#session-3--why-ai-products-are-different-)
  - [Session 4 : Human Behavior](#session-4--human-behavior)
  - [Session 5 : Emotional Design](#session-5--emotional-design)
  - [Session 6 : Behavioral Science](#session-6--behavioral-science)


## Session 1 : Introduction
Posted Jan 6
Course Introduction

Technology–Design–Humans Triangle framework: feasibility, usability, desirability

Google’s Page Algorithm 
Amazon’s order picker 
Xbox / Playstation use of computer vision 
CES 2026

## Session 2 : Product Management

- **PRODUCT MANAGEMENT: OVERVIEW AND DEFINITIONS**
    - **The Role of the Product Manager (PM)**
        - **The "CEO of Product" Myth**
            - The role is often referred to as the "CEO of the product".
            - Julia Austin (Harvard Business School) disagrees because PMs do not have direct authority over most resources (engineering, design, sales) needed to make the product successful.
            - Roles vary widely depending on the company, product type, and culture.
        - **Formal Definitions**
            - **Business Process:** Product management is the process of planning, developing, launching, and managing a product or service.
            - **Lifecycle:** It covers the entire lifecycle from ideation to development to go-to-market.
            - **Key Responsibility:** PMs ensure the product meets the target market's needs and contributes to business strategy.
            - **ProdBOK Definition:** The process of conceiving, planning, developing, testing, launching, delivering, and withdrawing products in the market.
        - **Scope of Work**
            - **Internal:** Working with current teams and management.
            - **External:** Managing supply chain and market.
            - **Upstream:** Planning, development, launch.
            - **Downstream:** Ongoing lifecycle management.
            - **Purpose:** Create customer value and measurable business benefits.

    - **Metaphors for Product Management**
        - **The Chef:** Creates a menu (vision), gathers ingredients (resources), cooks dishes (develops features), serves them (launches), and gets feedback (measures).
        - **The Movie Director:** Creates a story (vision), hires actors/crew (resources), shoots scenes (develops features), edits (launches), and gets reviews (measures).
        - **The Teacher:** Designs curriculum (vision), prepares lessons (resources), teaches (develops features), grades assignments (launch), and gets feedback (measures).
        - **The Architect:** Designs a building (vision), hires contractors (resources), oversees construction (develops features), delivers it (launch), and gets feedback (measures).

- **CORE COMPETENCIES**
    - **Overview**
        - These are baseline skills every PM must have. Many start in the classroom but are honed through experience, role models, and mentoring.
        - The best PMs reflect on these competencies to adjust their approach based on feedback.
    - **List of Essential Competencies**
        1. Conducting customer interviews and user testing.
        2. Running design sprints.
        3. Feature prioritization and road map planning.
        4. The art of resource allocation (noted as an art, not a science).
        5. Performing market assessments.
        6. Translating business-to-technical requirements, and vice versa.
        7. Pricing and revenue modeling.
        8. Defining and tracking success metrics.

- **EMOTIONAL INTELLIGENCE (EQ)**
    - **Importance**
        - High EQ is critical for navigating internal/external hurdles and building strong relationships.
        - Based on Daniel Goleman’s four key traits.
    - **1. Relationship Management**
        - Vital for negotiation, resolving conflicts, and working toward shared goals.
        - **Challenge:** Balancing the needs of customers, resource-constrained engineering teams, and revenue goals.
        - **Outcomes of strong relationships:**
            - Gaining support for additional funding.
            - Swaying engineers to include quick bug fixes.
            - Encouraging existing customers to beta test new features.
            - Convincing target customers to try an MVP in stealth mode.
            - Managing irate customers (turning them into supporters).
    - **2. Self-Awareness**
        - PMs must remain objective and avoid projecting personal preferences onto users.
        - **Risks of low self-awareness:**
            - **"False-positive feature validation":** Users say they love a feature just to please the PM.
            - **Derailment:** Prioritizing features customers don't want leads to lost confidence from engineers.
    - **3. Self-Management**
        - The role is stressful due to tight deadlines, revenue targets, conflicts, and constraints.
        - **Requirement:** Maintain composure. Push for priorities with urgency but without conveying panic.
        - **Strategy:** Know when to step away and regroup.
    - **4. Social Awareness**
        - Includes empathy, organizational awareness, and service.
        - **Understanding Constituents:**
            - **Customers:** Understand emotions and concerns.
            - **Sales/Support:** Understand how to sell and support the product.
            - **Engineering:** Understand how to build it.
        - **Social Capital:** Building influence to obtain budget, staffing, or secure top engineers.

- **COMPANY FIT**
    - **Evaluating a Role**
        - Success depends on applying skills in the right environment.
        - Factors: Product type, stage, industry, culture, and compensation.
    - **A. Technical Skill Requirements**
        - **Google:** Requires passing a technical skills test regardless of the product.
        - **SaaS CRM:** Requires experience with go-to-market and customer lifecycles.
        - **Data Science/ML Products:** Requires technical depth to understand the build and talk credibly with customers.
        - **Recommendation:** Aspiring PMs lacking skills should take courses like Harvard’s CS50 or Flatiron School courses.
    - **B. Company Philosophy on PM**
        - **1. PM Drives Engineering ("Throw it over the wall")**
            - **Process:** PM gathers requirements -> writes document -> hands to engineering.
            - **Pro:** Engineers focus on coding (good for waterfall).
            - **Con:** Engineers lose big picture/empathy; tension over technical debt vs. customer needs.
        - **2. Engineering Drives Product**
            - **Context:** Technical products (cloud, big data, networking).
            - **Process:** Engineers advance science; PMs validate solutions or build front-end access (UI/API).
            - **Pro:** Breakthrough technology customers didn't know they needed (e.g., VMotion at VMware).
            - **Con:** Over-architecting; chasing "shiny new things"; missing basic customer needs.
        - **3. The PM-Engineering Partnership (Yin-Yang)**
            - **Process:** Joint discovery, decision-making, and shared accountability.
            - **Roles:** PMs don't tell engineers *how* to code; Engineers don't dictate prioritization.
            - **Pro:** Streamlined prioritization, better UX, higher quality/velocity, happier customers.
            - **Con:** Innovation may lag; time-to-market may seem slower (but scales better).
            - *Note:* Julia Austin and Fred Wilson bias toward this model.
    - **C. Stage of Company**
        - **Startup**
            - **Scope:** Responsible for "all the things" (pricing, marketing, support, sales).
            - **Environment:** Scrappy, ambiguous, frequent changes.
            - **Pro:** Strategic involvement, exposure to leadership, high impact, influence over resources.
            - **Con:** No mentorship/best practices, tight budgets, requires learning on the fly.
        - **Mature Company**
            - **Scope:** Narrower; part of a larger PM team; support from specialized coworkers.
            - **Pro:** Mentorship, standards, established customer base/data.
            - **Con:** Less strategic exposure, "lost in the system," politics, just "one of many voices".
    - **D. Founder/Leadership Relationship**
        - In early-stage companies, PMs must assess how involved the Founder/CTO/CEO is.
        - **Risk:** If founders prefer driving product direction, PMs may feel undermined or reduced to execution only.

- **INDUSTRY VARIATIONS**
    - **Finance PM**
        - **Products:** Loans, insurance, investments, payments.
        - **Focus:** Regulations, competitive landscape, collaborating with analysts/vendors.
    - **Healthcare PM**
        - **Products:** Devices, software, diagnostics, treatments.
        - **Focus:** Patient/provider pain points, clinical evidence, compliance, ethics.
    - **Consumer PM**
        - **Products:** Food, clothing, entertainment.
        - **Focus:** Consumer desires, trends, brand identity, supply chain/retail safety.

- **TASKS AND EXECUTION**
    - **Common PM Tasks**
        - **Research & Analysis:** Understand customer needs, competition, and market trends to define the problem and value proposition.
        - **Develop Strategy:** Create vision and roadmap; align with company goals; prioritize based on impact/feasibility.
        - **Communicate:** Share vision with stakeholders (execs, engineers, designers, marketers) to gain buy-in.
        - **Coordinate:** Work with cross-functional teams to build to spec, within budget and timeline.
        - **Launch & Manage:** Execute go-to-market (pricing, positioning); monitor performance post-launch.
    - **Example: Microsoft Senior PM Responsibilities**
        - **Strategy:** Contributing to product vision, roadmap, and evangelizing ideas.
        - **Launch:** Creating demos and collateral.
        - **Prioritization:** "Ruthless prioritization" across competing objectives.
        - **Engineering/Design Engagement:** Partnering to understand trade-offs.
        - **Data:** Gathering data to measure effectiveness; formulating and validating hypotheses with prototypes.
    - **Role Specialization (Visual Model)**
        - **Product Marketer:** Focuses on outbound/market.
        - **Product Manager:** Focuses on value definition and engineering connection.
        - **Technical Product Champion:** Focuses on technical support details.
        - **Sales Product Champion:** Focuses on sales enablement.

- **PRODUCT DEVELOPMENT CONCEPTS**
    - **MVP vs. MMP vs. MLP**
        - **MVP (Minimum Viable Product):**
            - **Goal:** Confirm or refute software idea; collect feedback.
            - **Speed:** Fastest to develop.
            - **Features:** Minimum to check idea.
            - **UX:** Little attention to design ("Functional" layer only).
            - **Use case:** Effective with few rivals.
        - **MMP (Minimum Marketable Product):**
            - **Speed:** Fast to develop.
            - **Features:** Minimum to promote product at market.
            - **Use case:** Effective in different competition environments.
        - **MLP (Minimum Lovable Product):**
            - **Goal:** Win over early adopters; create emotional connection.
            - **Speed:** Slower than MVP.
            - **Features:** Minimum to gain user's following.
            - **UX:** Focus on lovable UI and enjoyable UX.
            - **Interaction:** Must "hook" the user; generates word-of-mouth.
            - **Hierarchy:** A slice through all layers: Functional, Reliable, Usable, and Design/UX.

- **AI-DRIVEN PRODUCT MANAGEMENT**
    - **The Shift: Pre-AI vs. AI Ecosystem**
        - **Pre-AI Role:**
            - Coordinators between business, design, engineering.
            - Focus: Requirement gathering, prioritization, roadmap execution.
            - Lifecycle: Linear (Requirements -> Design -> Build -> Test -> Launch).
        - **AI Ecosystem Role:**
            - Translators between AI researchers, engineers, and stakeholders.
            - Focus: Data science, ML workflows, ethical implications.
            - Lifecycle: Iterative & Experimental (Data Collection -> Training -> Validation -> Deployment -> Monitoring -> Model Drift -> Retraining).
    - **Metrics, Risks, and Skills**
        - **Metrics of Success (AI):**
            - Model performance (Precision, Recall, F1 score).
            - Fairness, Transparency, Ethical compliance.
        - **Risks (AI):**
            - Algorithmic bias, Data privacy, Unintended consequences, Regulatory compliance.
        - **New Skills Required:**
            - Data literacy, AI ethics, Experimentation design, Evaluating technical trade-offs.
        - **Collaboration:**
            - Includes Data scientists, ML engineers, AI ethicists, Legal compliance.
    - **Tools (e.g., Lovable)**
        - **Agent Orchestration:** Design intelligent agents without deep coding.
        - **Rapid Prototyping:** Test workflows before committing engineering resources.
        - **Risk Management:** Embed ethical checks (bias detection).
        - **Role Shift:** Helps PMs move from "feature coordinators" to "ecosystem orchestrators".

- **SOFT SKILLS**
    - **Essential List**
        - Leadership, Team Building, Motivation, Communication, Influencing, Decision Making, Political & Cultural Awareness, Negotiation, Trust Building, Conflict Management, Coaching.

## Session 3 : Why AI Products are different ?

Edited Jan 13
1) AI, ML, DL 101. Why AI is NOT needed in every use case

2) Why AI is different?
Servitization : Servitization is a business strategy where companies shift from just selling products to offering integrated products and services, creating new revenue streams and deeper customer relationships by focusing on outcomes and customer experience, often using digital tech.

3) Products vs Services

4) Customer Experience

**Course and Instructor Details**
- **Course Name:** The Business of Artificial Intelligence (DES 530)
- **Institution:** IIIT Delhi
- **Instructor:** Dr. Vinish Kathuria

**1. Customer Experience (CX)**

- **Definitions and Scope**
    - **General Definition:** Customer experience (CX) is the totality of cognitive, affective, sensory, and behavioral consumer responses during all stages of the consumption process. This includes pre-purchase, consumption, and post-purchase stages (Norris & Metcalf, 2021).
    - **Touchpoints:** Forbes describes CX as the "cumulative impact of multiple touchpoints" over the course of a customer's interaction with an organization.
    - **Segmentation of Interaction:**
        - Some companies segment experience into interactions via the web and social media.
        - Others define it as human interaction, such as over-the-phone customer service or face-to-face retail service (Zwilling, 2014).
    - **Value Creation:** CX is about adding value for customers buying products and services through customer participation and connection by managing all aspects of the encounter.
    - **Occurrence:** Experiences occur when consumers search for products, shop for them, receive services, and consume them (Brakus et al., 2009).

- **Impact on Business**
    - **Differentiation:** A company's ability to deliver an experience that sets it apart increases consumer spending and inspires brand loyalty.
    - **Loyalty Drivers:** Loyalty is now primarily driven by a company's interaction with its customers and how well it delivers on their wants and needs.
    - **Bottom Line:** Creating strong, positive experiences within the customer journey improves the bottom line through improved customer loyalty and word of mouth (Harmeling, 2017).
    - **Artifacts:** Companies do not sell customer experience; instead, they provide artifacts and contexts conducive to experiences (Brakus et al., 2009).

- **Types of Experiences (Brakus et al., 2009)**
    - **1. Product Experience:** Occurs when consumers interact with products (e.g., searching, examining, and evaluating products) (Hoch, 2002),.
    - **2. Shopping and Service Experience:** Happens when a consumer interacts with a store’s physical environment, personnel, policies, and practices (Kerin et al., 1992).
    - **3. Consumption Experience:** Multidimensional experiences that include hedonic dimensions, such as feelings, fantasies, and fun (Holbrook & Hirschman, 1982).

**2. The Customer Journey**

- **Overview**
    - Lemon & Verhoef (2016) conceptualized three cyclical stages to highlight the nature of the customer journey: Pre-purchase, Purchase, and Post-purchase.

- **Stage 1: Pre-purchase**
    - **Scope:** Encompasses all aspects of the customer’s interaction with the brand, category, and environment before a purchase transaction.
    - **Process:** Begins with need/goal/impulse recognition and moves to the consideration of satisfying that need with a purchase.
    - **Behaviors:** Need recognition, consideration, search.
    - **Touch Points:** Brand owned, Partner owned, Customer owned, Social/external.

- **Stage 2: Purchase**
    - **Scope:** Covers all customer interactions with the brand and its environment during the purchase event.
    - **Behaviors:** Choice, ordering, payment.

- **Stage 3: Post-purchase**
    - **Scope:** Encompasses customer interactions with the brand and its environment following the purchase.
    - **Behaviors:** Usage, consumption, post-purchase engagement, and service requests.
    - **Outcomes:** Triggers may lead to customer loyalty (repurchase) or begin the process anew with the customer re-entering the pre-purchase phase.

**3. The Consumer AI Experience**

- **Dimensions of Experience**
    - Consumer experience relates to interactions during the journey and encompasses multiple dimensions: **Emotional, Cognitive, Behavioral, Sensorial, and Social** (Lemon and Verhoef 2016; Puntoni et al., 2021).

- **Puntoni et al. (2021) Framework: AI Capabilities vs. Consumer Experience**
    - **1. Listening Capability -> Data Capture Experience**
        - **Description:** The experience of endowing individual data to AI.
        - **Psychological Tension:** Served vs. Exploited.
        - **Sociological Context:** Surveillance Society.
    - **2. Predicting Capability -> Classification Experience**
        - **Description:** The experience of receiving AI’s personalized predictions.
        - **Psychological Tension:** Understood vs. Misunderstood.
        - **Sociological Context:** Unequal Worlds.
    - **3. Producing Capability -> Delegation Experience**
        - **Description:** The experience of engaging in production processes where the AI performs some tasks on behalf of the consumer.
        - **Psychological Tension:** Empowered vs. Replaced.
        - **Sociological Context:** Transhumanism.
    - **4. Interacting Capability -> Social Experience**
        - **Description:** The experience of interactive communication with an AI partner.
        - **Psychological Tension:** Connected vs. Alienated.
        - **Sociological Context:** Humanized AI.

**4. Goods, Services, and Service-Dominant (S-D) Logic**

- **Goods vs. Services: Key Differences**
    - **Goods:**
        - **Definition:** Tangible, physical items (furniture, electronics) that can be bought, sold, owned, and stored.
        - **Tangibility:** Physical objects you can see, touch, and feel.
        - **Ownership:** Transferred from seller to buyer.
        - **Storage:** Can be produced, inventoried, and sold later.
        - **Separability:** Production is separate from consumption.
        - **Consistency:** Typically standardized and produced to be identical.
    - **Services:**
        - **Definition:** Intangible actions or experiences (healthcare, education) consumed as provided.
        - **Intangibility:** Cannot be physically held or stored.
        - **Ownership:** Customer experiences a benefit/outcome; does not own the service.
        - **Storage:** Cannot be inventoried; consumed as produced.
        - **Inseparability:** Production and consumption often happen simultaneously.
        - **Variability:** Often inconsistent; quality depends on provider and customer preferences.

- **Service-Dominant (S-D) Logic**
    - **Definition:** A theoretical proposal highlighting a paradigm shift from goods-dominant logic to service-dominant logic.
    - **Role of Customer:** Customers are value creators. Value is **co-created** via user preferences, playlists, and engagement (e.g., Spotify).
    - **Key Premises:**
        - **FP1:** Service is the fundamental basis of exchange. (Service is the application of operant resources like knowledge and skills).
        - **FP6:** The customer is always a co-creator of value (Implies value creation is interactional).
        - **FP9:** All economic and social actors are resource integrators (Context is networks of networks).
        - **FP10:** Value is uniquely and phenomenologically determined by the beneficiary (Value is idiosyncratic, experiential, contextual, and meaning-laden).

**5. Key Terms in AI and Human-Machine Interaction**

- **Artificial Intelligence:** Programs, algorithms, systems, and machines that exhibit aspects of human intelligence and provide means to interpret external data correctly, learn from such data, and exhibit flexible adaptation (Huang & Rust, 2018; Davenport et al., 2020).
- **Smart Objects:** Physical devices or assemblages of devices, such as bright lights, intelligent homes, robot pets, smart cars, or virtual assistants like Amazon Alexa (Novak & Hoffman, 2018).
- **Intelligent Machines:** Digital technologies that feature data-driven forms of customization, learning, and autonomous action (Osterlund et al., 2020).
- **Voice AI:** Conversational AI tool that uses voice commands to receive and interpret directives (Klaus & Zaichowsky, 2022).
- **Service AI:** The configuration of technology to provide value in the internal and external service environments through flexible adaptation enabled by sensing, learning, decision-making, and actions (Bock et al., 2020).
- **Automation:** Technology by which a process or procedure is performed with minimal human assistance (Groover, 2014).
- **Personalization:** Occurs when the firm decides, usually based on previously collected customer data, what marketing mix is suitable for the individual (Arora et al., 2008).
- **Trust:** A three-dimensional construct composed of competence, integrity, and benevolence; provides the trustor confidence that the trustee will behave capably, ethically, and fairly (Pavlou & Fygenson, 2006).
- **AI-Driven Consumer Products:** Products bringing together technologies (ML, knowledge representation, NLP, computer vision, robotics) to endow machines with increasingly human-like physical, cognitive, and emotional capabilities (Castelo, 2019),.
- **Human Machine Interaction (HMI):** Communication and interaction between a human and a machine via a user interface (Simao et al., 2018).
- **Humanized AI:** Refers to the human-like traits of the machines (Miao et al., 2018).
- **Explainable AI (XAI):** Artificial intelligence in which the results of the solution can be understood by humans (Rudin, 2019).
- **Human Machine Communication (HMC):** Explores interactions with technologies designed as communicative subjects instead of mere interactive objects (Guzman and Lewis, 2020).
- **Human-Centered AI:** Integrates AI technologies with human-computer interaction approaches, shifting from emulating humans to empowering people; suggests high levels of human control and computer automation are possible (Shneiderman, 2020).
- **Anthropomorphism:** The application of humanlike attributes (personality, verbal/nonverbal behaviors, politeness) to non-human objects (Schuetzler et al., 2020).

- **Additional Notes on AI-Driven Products**
    - **Capabilities:** Ability to learn from user behavior patterns and personalize the experience (Huang & Rust, 2017).
    - **Servitization:** Transforms stand-alone products into services by giving them "senses" and "intelligence" to render judgments.
    - **Transition:** Shift from technologies as intermediaries (people talk *through* them) to communicators (people talk *with* them).
    - **Expectations:** Higher perceived quality (product view) combined with higher involvement and emotions (service view).

**6. Technology Evaluation of AI Startups (VDAT Framework)**

- **Problem Identification**
    - **The Key:** Use AI intelligently for problems that *require* it, not just basic automation.
    - **Rules vs. AI:**
        - *Rules/Automation:* Best for fixed, narrow range inputs/outputs (e.g., closing books). Inputs are quantifiable numbers; output is determined by static rules,.
        - *AI/Deep Learning:* Best for unpredictable points, chaotic inputs (e.g., security vulnerability points, visual inputs for self-driving cars, voice assistants in vernacular domains),.

- **The VDAT Framework**
    - **1. Variety in Data**
        - Of the 3 Vs (Volume, Velocity, Variety), **Variety** plays the biggest role in AI.
        - Crucial for systems handling infinite/chaotic varieties of inputs (e.g., unauthorized network intrusions).
    - **2. Data Acquisition**
        - Requirement: Vast quantities of data for ML/Deep Learning.
        - Sources: Publicly available data, firm’s own unique data, customer/partner provided data.
        - **Strategy:** Must acquire and integrate data from multiple sources in a cost-effective manner.
        - **Considerations:** GDPR/Regulatory restrictions.
        - **Network Effect:** System improves as volume of data increases (more value to individual user even if they only interact with a sliver of data).
        - **Data Moat:** Competitive advantage held because of a proprietary data set.
    - **3. Architecture**
        - Must be scalable in line with long-term company vision (enterprise-grade).
        - **Sound Data Architecture:** Required to fully utilize huge amounts of data from different sources.
        - **Time-Frame:** Determined by the problem (e.g., obstacle detection = real-time; borrower credit scores = delayed),.
        - **Hosting:** On-premise, public cloud, or hybrid (decided by product requirements and client data policies).
    - **4. Talent Acquisition**
        - **Requirement:** Collaboration between domain experts and AI experts.
        - **Leadership:** Entrepreneurs must understand talent needs and hire those more knowledgeable than themselves in specific fields.

**7. Digital Service Innovation (DSI) for Smarter Production (Academic Study)**

- **Study Overview**
    - **Title:** Digital service innovation for smarter production: Servitized-AI progress towards smart products.
    - **Authors:** Esteban Lafuente, Yancy Vaillant, Ajax Persaud.
    - **Objective:** Investigate if simultaneous integration of servitization and AI-intensive strategies leads manufacturers to develop products with more advanced analytically 'smart' capabilities.

- **Core Concepts**
    - **Smart Products:** Products equipped with sensors, connectivity, analytical software, and algorithms enabling remote monitoring, control, optimization, and autonomy.
    - **Digital Service Innovation (DSI):** Transforming the development and delivery of servitization-augmented products by harnessing digital technologies (AI, Cloud, IoT). Focuses on creating new digital services,.
    - **Servitization:** Service-centric business models where producers bundle products with services to deliver higher value.
    - **Digital Servitization vs. DSI:**
        - *Digital Servitization:* Strategic transition to product-service systems.
        - *DSI:* Creation/advancement of new digital services (AI-augmented) delivering novel customer value.
    - **Structurational Model (Orlikowski, 1992):** Technology is both a shaping force and a product of strategic decisions. AI and servitization are part of a strategic value generation system.

- **Smart Product Capability Scale (Nested Structure)**
    - 1. **Monitoring:** Use of sensors and external data sources for real-time alerts and usage insights.
    - 2. **Control:** Bidirectional interaction allowing remote operation and personalization via embedded/cloud software.
    - 3. **Optimization:** Use of algorithms/analytics to enhance efficiency, predictive maintenance, and minimize downtime.
    - 4. **Autonomy:** Products operate independently, self-diagnose, adapt to preferences, and self-coordinate with other systems.

- **Hypotheses**
    - **H1:** Servitization adoption has a significant positive role on producing smarter products (progression towards autonomy).
    - **H2:** AI-intensive strategy adoption has a significant positive role on producing smarter products.
    - **H3:** The **joint implementation** of servitization and AI-intensive strategies significantly contributes to producing smarter products (specifically towards autonomy).

- **Methodology**
    - **Sample:** 576 Spanish manufacturing firms (Data collected 2023),.
    - **Method:** Ordered probit model with sample selection (Heckman model),.
    - **Variables:**
        - *Dependent:* Smartness level (Monitoring, Control, Optimization, Autonomy).
        - *Independent:* Servitization (Binary), AI-intensive strategy (Binary), Interaction term,.
        - *Controls:* Firm size, age, industry, location.

- **Key Findings**
    - **Servitization Impact:** Servitized firms are more likely to produce products higher up the smart scale (H1 confirmed).
    - **AI Impact:** AI-intensive strategies make producers more likely to generate smarter products (H2 confirmed).
    - **Joint Impact (DSI):**
        - The positive association with advanced/autonomous capabilities is found **when servitization and AI-intensive strategies are jointly implemented**,.
        - For firms implementing only one strategy (either/or), the adoption was *not* found to play a positive role in progressing towards *fully* autonomous capabilities in the second outcome model.
        - Simultaneous adoption is especially effective for **optimization and autonomy** capabilities,.

- **Statistics from Sample**
    - 21.70% of firms with digitalized products are at the 'monitoring' stage.
    - 12.67% are at the 'control' stage.
    - 8.34% are at the 'optimization' stage.
    - Only 6.60% had products with fully 'autonomous' smart capabilities,.
    - 67% of firms with digitalized products provide combined product-service offerings (servitized).

- **Implications**
    - **Academic:** DSI acts as a catalyst for digital servitization. Servitization provides value logic/relational infrastructure; AI provides cognitive/autonomous capacity,.
    - **Managerial:** R&D investments for smart capabilities may fail if the firm hasn't consolidated both service-intensive and AI-driven capacities.
    - **Technification:** Customer benefits depend on the technification (smartness) of the products supplied.

## Session 4 : Human Behavior
Posted Jan 16
Key learnings from Psychology and Sociology

- **Human Behaviour 101**
  - **Course Info:** DAIDP 2026 - Understanding Human Behaviour Before Building Systems
  - **Core Concept: What Humans Need First**
    - **Fundamental Questions:**
      - What are your needs in life?
      - Do some needs hold more importance than others?
    - **Principle:** Humans have an order of needs. Lower order needs must be met before considering higher order needs.

  - **Maslow’s Hierarchy of Needs** (From top to bottom)
    - **Self-actualization:** morality, creativity, spontaneity, problem solving, lack of prejudice, acceptance of facts.
    - **Esteem:** self-esteem, confidence, achievement, respect of others, respect by others.
    - **Love/Belonging:** friendship, family, sexual intimacy.
    - **Safety:** security of body, of employment, of resources, of morality, of the family, of health, of property.
    - **Physiological:** breathing, food, water, sex, sleep, homeostasis, excretion.

  - **Group Project Scenarios: Group Dynamics**
    - **Scenario A (Negative Dynamic):**
      - 1. One person dominates all decisions.
      - 2. Your ideas are regularly shut down.
      - 3. Mistakes are mocked.
      - 4. You’re told: “Just do what I say”.
      - 5. You’re afraid to ask questions.
      - **Outcome:** This group usually gets a high grade.
    - **Scenario B (Positive Dynamic):**
      - 1. Everyone is encouraged to speak.
      - 2. Ideas are discussed, not dismissed.
      - 3. Mistakes are treated as learning.
      - 4. Feedback is respectful.
      - 5. You feel comfortable saying “I don’t understand.”
      - **Outcome:** The final grade is not guaranteed.

  - **Application in AI Design**
    - **Why this matters:** AI products enter human lives, not empty brains.
    - **The Rule:** If an AI system feels unsafe, threatening, or disrespectful, people won’t care how smart it is. **Human needs come before intelligence.**
    - **Mapping Maslow's Needs to Design/UX and AI Products:**
      - **Physiological → Functionality**
        - The AI product must perform its core task correctly (e.g., a language app teaches words, a medical AI assists with diagnosis).
      - **Safety → Reliability & Security**
        - The AI must work consistently and protect user data (e.g., a banking AI ensures secure transactions and consistent performance).
      - **Love/Belonging → Usability & Social Interaction**
        - The product must be easy to use and facilitate community or team collaboration (e.g., an AI work tool enables seamless communication among team members).
      - **Esteem → Proficiency & Personalization**
        - The AI should empower users to achieve more or become better at tasks through features like personalized recommendations or adaptive learning (e.g., a fitness app celebrates milestones).
      - **Self-Actualization → Creativity & Meaning**
        - The product provides a delightful, inspiring experience that allows users to express their individuality or find greater purpose (e.g., AI tools that help users explore creative pursuits or contribute to a broader social mission).

- **Cognitive Load Theory (CLT)**
  - **The Brain's Limits ("Why Your Brain Says Nope")**
    - Sometimes the brain refuses to work even when you are capable.
    - **Visual Distraction:** Every visual distraction demands a piece of the user’s limited cognitive resources, potentially derailing them from their intended task.
    - **Example of Overload:** Unhelpful error messages or complex forum debates (e.g., Stack Overflow threads about dev environments) can cause a user to think something is wrong with them or the tool.

  - **Memory Model**
    - **Flow:** Input → Observation → Sensory Memory → Selection → Working Memory → Performance.
    - **Interactions:**
      - **Working Memory:** Tiny capacity (in the "now").
      - **Long-term Memory:** Huge capacity (accumulates over time).
      - **Process:** Working memory handles Organization (internal) and Retrieval (from Long-term memory) and Transfer (to Long-term memory).
    - **Critical Failure:** If working memory overloads → learning stops. **When too much hits together → thinking breaks.**

  - **Types of Cognitive Load**
    - **Intrinsic Load:** The task itself is hard (e.g., Learning recursion, Understanding a new algorithm).
    - **Extraneous Load:** Bad presentation adds effort (e.g., Messy code, Cluttered UI, Walls of text).
    - **Germane Load:** Effort that builds understanding (e.g., Step-by-step explanations, Examples & patterns).

  - **Design Goal:** Remove extraneous, manage intrinsic, encourage germane.
    - **Example:** Coding with GitHub Copilot helps manage these loads.

- **Actor-Network Theory (ANT)**
  - **Definition:** A sociological theory developed by Bruno Latour, Michel Callon, and John Law.
  - **Purpose:** To explain scientific and technological activity without separating "social" and "technical" aspects.
  - **Core Concepts:**
    - Treats humans and non-humans as equal "actors" in shaping social and technical outcomes.
    - For any actor to act, many others must act as well; **action is always distributed across a network**.
    - Actors (human/non-human, individual/collective) are not the starting point of action; their constitution is explained through relationships.
    - **Control:** No single actor has full control or ownership over an action or outcome.

  - **Example: Google Maps Navigation**
    - Decision-making is distributed across a network of human and non-human actors.
    - **The Network:**
      - Users choose destinations.
      - Drivers share location data.
      - Planners shape infrastructure.
      - AI routing algorithms, GPS satellites, traffic sensors, and real-time data guide routes.
    - **Outcome:** Navigation emerges from continuous coordination among these actors; neither users nor AI act independently.

- **Social Identity Theory (SIT)**
  - **Origin:** Proposed by Henri Tajfel & John Turner (1979).
  - **Definition:** Explains how and why people define themselves based on the groups they belong to, and how this affects behavior, attitudes, and intergroup relations.
  - **Self-Concept:** People define themselves by:
    - **Personal identity:** Individual traits.
    - **Social identity:** Group belonging.
  - **Core Motto:** *“Part of who I am comes from the social groups I belong to.”*

  - **Key Processes in SIT**
    - **Social Categorisation:** Classifying people into groups (Us vs Them).
    - **Social Identification:** Adopting group identity and norms (We Belong!).
    - **Social Comparison:** Comparing groups to maintain positive self-esteem (We’re Better!).
      - Leads to **In-Group Favoritism** and **Out-Group Bias**.

  - **Example: The Apple Ecosystem**
    - Apple users form a strong in-group identity (“Apple ecosystem”).
    - Products signal creativity, premium quality, and innovation.
    - Design consistency reinforces group belonging.
    - Ecosystem lock-in strengthens social identification.
    - Subtle out-group distinction exists vs Android/Windows users.

- **Social Role Theory (SRT) & Authority**
  - **Concept:** Humans are "social detectives" who use mental scripts to assign roles based on norms and expectations.
  - **The Four Primary Archetypes**
    - **Servant:** Low autonomy; strictly follows direct commands (e.g., a basic calculator).
    - **Advisor:** High knowledge, low power; suggests "best" paths but leaves the final choice to the user (e.g., Grammarly).
    - **Partner:** Equal status; collaborates on a goal where both parties contribute unique value (e.g., a co-pilot for coding).
    - **Master:** High power; makes decisions that the user must follow (e.g., an automated safety brake).

  - **AI and Authority**
    - **AI as Legal-Rational Authority:** AI is the ultimate form of Legal-Rational Authority. It doesn't have a "mood", it has a procedure.
    - **Trust:** We trust it because it represents "objective" logic.
    - **Legitimacy:** AI systems embody authority through algorithms perceived as “objective” or “fair.”
    - **Max Weber’s Theory of Authority:** Power is obeyed when seen as legitimate. Three types:
      - **Traditional:** Kings.
      - **Charismatic:** Heroes.
      - **Legal-Rational:** Rules/bureaucracy.

  - **Hegel’s Dependence Paradox**
    - **Theory:** Hegel argued the Master depends on the Servant’s labor to function. Eventually, the Servant gains "self-consciousness" through work, while the Master becomes helpless.
    - **AI Application:** As we delegate cognitive tasks like coding and writing, humans may become dependent on the system for basic functions.
    - **The Design Dilemma:** Designers must debate if AI should remain a "Servant" or evolve into a Partner to keep the human "Master" skilled and engaged.

- **Summary: Theories in AI Design**
  - **Maslow’s Hierarchy of Needs**
    - *Discipline:* Psychology
    - *Core Idea:* Human motivation progresses from basic needs to self-actualization.
    - *AI Design Implication:* AI must align with user needs at different levels (safety, belonging, esteem, growth).
  - **Cognitive Load Theory (CLT)**
    - *Discipline:* Psychology
    - *Core Idea:* Working memory has limited capacity; learning depends on managing load types.
    - *AI Design Implication:* AI should reduce overload, scaffold complexity, and enhance meaningful learning.
  - **Actor-Network Theory (ANT)**
    - *Discipline:* Sociology
    - *Core Idea:* Humans, AI, institutions, and data are all “actors” shaping outcomes in networks.
    - *AI Design Implication:* AI must be analyzed as part of socio-technical ecosystems, not isolated tools.
  - **Social Identity Theory (SIT)**
    - *Discipline:* Sociology
    - *Core Idea:* People’s behavior is shaped by group membership and identity.
    - *AI Design Implication:* AI must avoid reinforcing bias and should foster inclusive group representation.
  - **Social Role Theory (SRT)**
    - *Discipline:* Sociology & Psychology
    - *Core Idea:* People assign roles (servant, master, advisor, partner) based on norms.
    - *AI Design Implication:* AI design must clarify its intended role to avoid mistrust or misuse.

## Session 5 : Emotional Design
Posted Jan 20

- **Emotional Design 101**
    - **Authors**: Anushka Korlapati, Riya Jain, Shubhi Jain
    - **Core Question**: Imagine you walk into your favorite coffee shop... What makes it your favorite?
    - **Decision Making Factors**:
        - We make choices based on three factors, not just one:
            1. **Satisfaction**
            2. **Emotion**
            3. **Trust**
        - **Key Insight**: Emotions often matter **MORE** than satisfaction alone.

- **The Three Pillars of Customer Experience**
    - **1. Satisfaction**
        - **Definition**: A judgment by the consumer that a product or service feature provides a pleasurable level of consumption-related fulfillment.
        - **Scope**: This includes levels of **under-or-over fulfillment** (Oliver, 1997).
    - **2. Emotion**
        - **Definition**: Adaptive mental and physiological feeling states that direct consumer attention and guide behavior.
        - **Types of Emotion**:
            - **Positive emotion**: An energized and alert state of mind.
            - **Negative emotion**: A state of distress or aversive mood (Watson & Clark, 1997).
    - **3. Trust**
        - **Definition**: A three-dimensional construct composed of:
            - **Competence**
            - **Integrity**
            - **Benevolence**.
        - **Function**: It provides the trustor with the confidence that the trustee will behave **capably, ethically, and fairly** (Pavlou & Fygenson, 2006).

- **The Evolution of Emotional Design**
    - **Core Philosophy**: Good products work. Great products feel right.
    - **Visual Examples**:
        - Spotify 2025 Wrapped.
        - Apple iPhone unboxing experience.
        - Duolingo characters.
    - **The Three Levels of Emotional Design**:
        - These distinct layers shape user experiences, focusing on the emotional journey, user engagement, and lasting connections.

    - **Level 1: Visceral Design**
        - **Concept**: **Love at first sight**.
        - **Focus**: Beyond functionality, this layer emphasizes **aesthetics**.
        - **Action**: Choosing visuals to evoke emotions.

    - **Level 2: Behavioral Design**
        - **Concept**: **Joy in interaction**.
        - **Focus**: Design meets user needs efficiently.
        - **Action**: The product should be intuitive and easy to navigate, forming a solid **usability foundation**.

    - **Level 3: Reflective Design**
        - **Concept**: **Design to remember the experience**.
        - **Focus**: This level creates deep emotional connections.
        - **Action**: Uses relatable experiences and meaningful interactions.

    - **The Intersection: Enduring Pleasure**
        - **The Meeting Point**: The intersection of Visceral, Behavioral, and Reflective design leads to **DELIGHT!**.
        - **Definition**: That intersection refers to the **Enduring Pleasure**.
        - **Approach**: This is known as a **People-First Design Approach**.

- **Critical Analysis: Ethics and Well-being**
    - **The Problem**: Emotional design isn’t just about adding "delight".
    - **Case Study (Instagram)**: Do you trust that Instagram is designed for **YOUR** wellbeing?.
    - **The Consequence**:
        ```text
        "Teen anxiety spiked after 2012; when phones replaced play."
        — Jonathan Haidt, NYU
        ```

- **Design Framework: Recognizing and Fixing Emotional Failures**
    - **Guiding Principle**:
        ```text
        "We are emotional beings, and our emotions guide how we behave, what we trust, and what we remember. Good design understands this and works with it; not against it."
        — Don Norman
        ```
    - **Step 1: Identify "What's Emotionally Broken?"**
        - Identify the **negative emotion** it creates.
        - Identify which **trust dimension** fails:
            - **Competence**
            - **Integrity**
            - **Benevolence**.
        - Identify the **root cause** (examples include tone, timing, manipulation, privacy violation, etc.).
    - **Step 2: Fix the Failure**
        - **Goal**: Fix the emotional failure while keeping functionality.
    - **Step 3: Justify the Trade-off**
        - **Analyze Potential Loss**: What business metric might decrease? (e.g., clicks, engagement, conversions).
        - **Analyze Potential Gain**: What improves instead? (e.g., trust, loyalty, retention, reputation).

- **Class Exercise: Redesign This Interaction Disaster**
    - **Scenario 1: Academic Integrity**
        - **Student**: “Can you help me with this essay?”
        - **AI**: “I’ll write it for you!”.
    - **Scenario 2: Aggressive Marketing**
        - **Aggressive AI marketing emails**: "Why haven't you bought yet?".

## Session 6 : Behavioral Science
Posted Jan 16
Behavioral science at Google involves applying psychology and economics to understand user actions, shaping product design (like changing "eligible" to "earned"), improving user experience (UX), personalizing content, and enhancing marketing through principles like framing, social proof, and authority bias, helping them make decisions and interact with digital services more effectively and intuitively. Key areas include understanding fast/unconscious "System 1" thinking, digital amnesia (the "Google Effect"), and building trust through transparency in decision-making.

Key Applications at Google

Product Design & UX: Using insights to make interfaces intuitive, like the "Google Effect" (forgetting info online) influencing search design.
Marketing & Ads: Applying principles like the Power of Free, Authority Bias, and Framing to make ads more persuasive on Search.

Personalization: Tailoring experiences based on observed behaviors.

Trust Building: Showing the "thought process" behind recommendations or issue resolution to increase user confidence.

Core Concepts Used

System 1/System 2 Thinking: Understanding fast, instinctual (System 1) versus slow, effortful (System 2) decision-making.

Choice Satisficing: Designing for users to find "good enough" solutions quickly, rather than overwhelming them with choices.
Framing & Costly Signaling:

Changing how information is presented (e.g., highlighting time savings) or associating products with premium qualities.

The "Google Effect" (Digital Amnesia)
A specific behavioral phenomenon where people forget information because they know it's easily searchable on Google, relying on the search engine as an external memory.

https://www.youtube.com/watch?v=NwCPtiPZwO4&authuser=3

- **Introduction and Background of Speaker**
    - The speaker is **Maya Shankar, PhD**, the Head of Behavioral Science at Google [Heading].
    - She was originally a **violinist**.
    - At age 17, she sustained a serious hand injury that doctors deemed a **career-ending diagnosis**.
    - She felt demoralized and worried she would never find a passion equal to the violin.
    - While helping her parents clean their basement, she found the book **"The Language Instinct"** by psychologist **Steven Pinker**.
    - She was mesmerized by the idea that language, which felt effortless to her, was actually the result of **extremely complicated, sophisticated cognitive architecture**.
    - This discovery propelled her to study **cognitive science** for 15 years to understand how the mind works.
    - She specialized in **decision science**.
    - **Key Insight**: Similar to language, decision-making feels effortless and intuitive, yet humans make **tens of thousands of decisions** every day.

- **Definition and Scope of Behavioral Science**
    - **Definition**: Behavioral science is the study of **how and why we make the decisions that we do**.
    - It includes research on how humans form **attitudes and beliefs** about the world.
    - It blends research from **psychology** and **economics** to provide a comprehensive understanding of decision-making patterns.
    - **Relevance**: Research shows human decisions are surprising and often influenced by factors that logically should not influence them.

- **Examples of Surprising Influences on Behavior**
    - **Voting Behavior**:
        - Voters should theoretically vote for the person they want elected.
        - Research in **Texas** showed that the **order** of names on a ballot has a significant impact.
        - When a candidate's name appeared **first**, they received **10 extra percentage points** in vote share.
        - This amount is enough to turn an election.
    - **Interpersonal Warmth**:
        - Research shows holding a **warm beverage** makes people feel more warmly toward those they interact with.
        - This is a **misattribution**: physical warmth is misinterpreted as interpersonal warmth.

- **Applied Behavioral Science: The Obama White House**
    - Shankar worked on **veterans' issues** in the Obama White House in 2015.
    - **The Problem**:
        - Veterans returning from overseas face challenges finding work and going back to school.
        - The federal government offered **free job assistance and educational counseling**.
        - **Not enough veterans were signing up** for these programs.
    - **The Solution**:
        - The team performed a behavioral analysis with no extra budget room.
        - They changed **one word** in the marketing message.
        - **Original Message**: Told veterans they were **eligible** for the program.
        - **New Message**: Reminded veterans they had **earned** it through their years of service.
    - **The Result**:
        - This single word change led to a **9% increase** in access to the program.
        - This had the potential to impact millions of veterans.
    - **Principle Illustrated: The Endowment Effect**.
        - This principle states that we **value things more** when we feel we have **earned them or own them**.

- **Application in Government Policy**
    - The goal was to build a team of behavioral scientists to engineer solutions for policy challenges.
    - They worked with the Department of Education, Department of Veterans Affairs, Health and Human Services, and the Department of Defense.
    - **Relevance to Healthcare/End-of-Life**:
        - Decisions are not made in a vacuum.
        - The **choice architecture** created for caregivers, providers, and patients matters.
        - This architecture influences end-of-life planning, human-centered solutions, and the minimization of implicit bias.

- **The Five Behavioral Science Principles**

    - **1. Social Identity Priming**
        - **Definition**: People tend to act in ways consistent with the identities they currently **associate with** or **aspire to associate with**.
        - **Red Cross Experiment**:
            - The Red Cross sent letters to previous donors asking for donations.
            - They ran an **A/B test**.
            - **Intervention**: They simply reminded recipients that they had been **previous donors**.
            - This **primed** their identity as charitable, generous people with "golden hearts".
            - **Result**: Identity priming led to a **30% increase** in charitable contributions.
            - It also increased the **magnitude** of donations relative to the previous year.
        - **Government Applications**:
            - **Unemployment**: Instead of calling people "claimants," they referred to them as **"job seekers"** to help them return to work.
            - **Re-entry**: Instead of "ex-convicts," they referred to people leaving prison as **"members of the community"** who are searching for work.
        - **Healthcare Application**:
            - In the health ecosystem, people occupy many roles.
            - Labeling is critical; subtle changes in how people are labeled can transform their **self-perception** and decision-making frameworks.

    - **2. User Agency and Control**
        - **Takeaway**: People like being in the **driver's seat**.
        - **Three Key Insights**:
            - **A. We like what we choose**:
                - When people actively choose something, they like it more.
                - Humans dislike **cognitive dissonance** and want to see themselves as good decision-makers.
                - We validate our choices by thinking, "I made a great decision".
            - **B. The IKEA Effect**:
                - We feel more **invested** in experiences we have contributed to.
                - Example: Even if you build an unsturdy stool from a box with "15 million pieces," you value it more than a pre-shipped item because you built it.
            - **C. Prediction of Outcomes**:
                - We predict better outcomes when we are in control.
                - Research shows people were more satisfied with an **algorithm** they were allowed to **tweak slightly**.
                - People opted to use the tweaked algorithm over other algorithms they *knew* performed better but did not involve their input.
                - This demonstrates **egocentricity**; we value our own contributions highly.
        - **Healthcare Application**:
            - It is crucial to maintain a patient's sense of **agency** over their health experiences.
            - Doctors must give patients options and empower them to question authority or give input on treatment plans.

    - **3. Operational Transparency**
        - **Definition**: Pulling the "curtain back" on the thought process or progress behind decisions helps build **trust**.
        - **City of Boston Example**:
            - Citizens complained about potholes and broken signs, viewing the government as a **"black box"** where nothing gets fixed,.
            - **Intervention**: The city created a **visual map** online.
            - It marked problems as **blue** (identified) and turned them **green** when fixed.
            - **Result**: Even though the speed of repairs **did not increase**, trust in government increased by **40%**.
            - Citizens became more **civically minded**.
        - **Healthcare Application**:
            - Provide patients and caregivers insight into **why** a diagnosis was made or **why** "Treatment Plan A" was chosen over "Treatment Plan B".
            - Showing the conclusion process is an effective way to build trust.
            - Patients privy to the thought process are more likely to **adhere** to the treatment.

    - **4. Memory Construction (The Peak-End Rule)**
        - **Concept**: Intuitively, we think every moment of an experience contributes equally to our memory of it.
        - **Reality**: We apply **disproportionate weight** to two specific points:
            - The most **intense moment** (the peak).
            - The **end** of the experience.
        - **Ice Water Experiment (Nobel Prize Research)**:
            - **Condition A**: Hands plunged into freezing ice water for **60 seconds**.
            - **Condition B**: Hands plunged into freezing ice water for **60 seconds**, followed by **30 seconds** where the water temperature was raised by **one degree Celsius** (still cold, but slightly less unpleasant).
                - Total time in discomfort: **90 seconds**.
            - **Result**: People preferred the **90-second experience** (Condition B).
            - Even though the duration of discomfort was longer, backing off the pain slightly at the end improved the memory of the experience.
        - **Healthcare Application**:
            - Important for designing unpleasant procedures (e.g., **colonoscopies**).
            - Easing the **end** of the experience improves memories.
            - Patients are more likely to **return** for follow-up visits and annual exams if the end is managed well.

    - **5. The Power of the Messenger**
        - **Concept**: The **messenger** matters significantly in behavioral research.
        - **Flint, Michigan Water Crisis Example**:
            - There was a lead in water crisis, and misinformation was spreading (e.g., people thought boiling water helped, but it actually concentrated the lead),.
            - The federal government (EPA) created safety fact sheets.
            - **The Problem**: There was a huge **breach of trust** between Flint residents and the government; the government seal might cause a "spillover effect" of distrust.
            - **The Solution**: The EPA mobilized **Canvassers** from within the community (Red Cross, YMCA, churches).
            - Trusted community members endorsed the fact sheets and delivered them door-to-door.
        - **Federal Student Aid Example**:
            - Goal: Motivate low-income students in HUD housing to fill out the **Free Application for Federal Student Aid**.
            - Initial letters from government agencies were less effective.
            - **Intervention**: Letters were sent from **Michelle Obama**.
            - She shared a **personal testimonial** about feeling like an underdog and questioning if she belonged at Princeton.
            - **Result**: This was extremely effective in motivating students to sign up.
        - **Healthcare Application**:
            - We must be thoughtful about **who** delivers the message in end-of-life care.
            - A lack of **psychological safety** with the messenger can deter people from making any decision at all.

- **Conclusion**
    - Behavioral science can enhance **policy design**.
    - It sheds light on how people make end-of-life decisions.
    - Policies and programs should be **optimized** with these insights to account for how people actually behave and think.